{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# importing all the required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "from skimage import exposure\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = os.listdir('images/')\n",
    "captions = os.listdir('captions_augmented/')\n",
    "image_path = 'all_caption_files/media/images_augmented/00001.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('all_caption_files/caption_data/dataset_DAMICA.json', 'r') as readfile:\n",
    "    dataset_orig = json.load(readfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset['images'])):\n",
    "    print(i)\n",
    "    \n",
    "    #Add appropriate image path\n",
    "    image_path = 'all_caption_files/media/images_augmented/'+ dataset['images'][i]['filename']\n",
    "    \n",
    "    if dataset['images'][i]['split'] == 'train':\n",
    "        \n",
    "        image = io.imread(image_path)\n",
    "        plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_1.jpg\" , image )\n",
    "        with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_1.txt', 'w+') as writefile:\n",
    "            writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "\n",
    "        rotated_90 = rotate(image, angle=90, resize= True)\n",
    "        plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_2.jpg\" , rotated_90 )\n",
    "        with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_2.txt', 'w+') as writefile:\n",
    "            writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        #rotated_180 = rotate(image, angle=180, resize= True)\n",
    "        #plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_3.jpg\" ,rotated_180 )\n",
    "        #with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_3.txt', 'w+') as writefile:\n",
    "            #writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        flipLR = np.fliplr(image)\n",
    "        plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_3.jpg\" ,flipLR )\n",
    "        with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_3.txt', 'w+') as writefile:\n",
    "            writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        flipUD = np.flipud(image)\n",
    "        plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_4.jpg\" ,flipUD )\n",
    "        with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_4.txt', 'w+') as writefile:\n",
    "            writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        #noisyRandom = random_noise(image,var=0.15**2)\n",
    "        #plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_5.jpg\" , noisyRandom )\n",
    "        #with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_5.txt', 'w+') as writefile:\n",
    "            #writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        #blurred = gaussian(image,sigma=3,multichannel=True)\n",
    "        #plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_7.jpg\" , blurred )\n",
    "        #with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_7.txt', 'w+') as writefile:\n",
    "            #writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        #image_bright = exposure.adjust_gamma(image, gamma=0.5,gain=1)\n",
    "        #plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_6.jpg\" , image_bright )\n",
    "        #with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_6.txt', 'w+') as writefile:\n",
    "            #writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "        image_dark = exposure.adjust_gamma(image, gamma=2,gain=1)\n",
    "        plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \"_5.jpg\", image_dark )\n",
    "        with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '_5.txt', 'w+') as writefile:\n",
    "            writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            \n",
    "    else:\n",
    "        image = io.imread(image_path)\n",
    "        plt.imsave(\"images_augmented/\" + os.path.split(image_path)[1].split(\".\")[0] + \".jpg\" , image )\n",
    "        with open('captions_augmented/' + os.path.split(image_path)[1].split(\".\")[0] + '.txt', 'w+') as writefile:\n",
    "            writefile.write(dataset['images'][i]['sentences'][0]['raw'])\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "image = []\n",
    "caps = []\n",
    "\n",
    "for i, j in zip(glob.glob('captions_augmented/*.txt'), glob.glob('all_caption_files/media/images_augmented/*.jpg')):\n",
    "    cap, img = os.path.split(i)[-1], os.path.split(j)[-1]\n",
    "    f = open('captions_augmented/'+ cap, \"r\")\n",
    "    caps.append(f.read())\n",
    "    image.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filename'] = image\n",
    "df['raw_caps'] = caps\n",
    "df['tokens']  = df['raw_caps'].apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for i in range(len(df)):\n",
    "    df['tokens'][i] = [w.translate(table) for w in df['tokens'][i]]\n",
    "    df['tokens'][i] = [w for w in df['tokens'][i] if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>raw_caps</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>By: K. Allen, PhD; A. Morhardt, PhD; T. Ritzma...</td>\n",
       "      <td>[By, K, Allen, PhD, A, Morhardt, PhD, T, Ritzm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002_1.jpg</td>\n",
       "      <td>Materials: gloves, forceps, probe, scissors, s...</td>\n",
       "      <td>[Materials, gloves, forceps, probe, scissors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002_2.jpg</td>\n",
       "      <td>Materials: gloves, forceps, probe, scissors, s...</td>\n",
       "      <td>[Materials, gloves, forceps, probe, scissors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00002_3.jpg</td>\n",
       "      <td>Materials: gloves, forceps, probe, scissors, s...</td>\n",
       "      <td>[Materials, gloves, forceps, probe, scissors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00002_4.jpg</td>\n",
       "      <td>Materials: gloves, forceps, probe, scissors, s...</td>\n",
       "      <td>[Materials, gloves, forceps, probe, scissors, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                           raw_caps  \\\n",
       "0    00001.jpg  By: K. Allen, PhD; A. Morhardt, PhD; T. Ritzma...   \n",
       "1  00002_1.jpg  Materials: gloves, forceps, probe, scissors, s...   \n",
       "2  00002_2.jpg  Materials: gloves, forceps, probe, scissors, s...   \n",
       "3  00002_3.jpg  Materials: gloves, forceps, probe, scissors, s...   \n",
       "4  00002_4.jpg  Materials: gloves, forceps, probe, scissors, s...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [By, K, Allen, PhD, A, Morhardt, PhD, T, Ritzm...  \n",
       "1  [Materials, gloves, forceps, probe, scissors, ...  \n",
       "2  [Materials, gloves, forceps, probe, scissors, ...  \n",
       "3  [Materials, gloves, forceps, probe, scissors, ...  \n",
       "4  [Materials, gloves, forceps, probe, scissors, ...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['images'] = {}\n",
    "dataset['dataset'] = 'DAMICA'\n",
    "dataset['images'] = [{\"sentids\":[i], \"imgid\":i, \"sentences\": [{\"tokens\": df['tokens'][i], \"raw\": df['raw_caps'][i], \"imgid\": i, \"sentid\": i}], \n",
    "                      \"split\": \"full_dataset\", \"filename\": df['filename'][i]} \n",
    "                     for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "population = [1, 2]\n",
    "weights = [0.5, 0.5]\n",
    "\n",
    "set_label = []\n",
    "for i in range(len(df)):\n",
    "    if '_' in df['filename'][i]:\n",
    "        set_label.append(0)\n",
    "    else:\n",
    "        set_label.append(choices(population, weights)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_label'] = set_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58510\n",
       "1     1449\n",
       "2     1435\n",
       "Name: set_label, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['set_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset['images'])):\n",
    "    if df['set_label'][i] == 2:\n",
    "        dataset['images'][i]['split'] = \"val\"\n",
    "    elif df['set_label'][i] == 1:\n",
    "        dataset['images'][i]['split'] = \"test\"\n",
    "    else:\n",
    "        dataset['images'][i]['split'] = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61394"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dataset_DAMICA_aug.json', 'w') as outfile:\n",
    "    json.dump(dataset, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
